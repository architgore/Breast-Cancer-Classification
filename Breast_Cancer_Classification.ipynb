{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxC/1qRj2hdjU8dwxXoe7y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/architgore/Breast-Cancer-Classification/blob/main/Breast_Cancer_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Breast Cancer Classification**\n",
        "\n",
        "Archit Gore"
      ],
      "metadata": {
        "id": "pZwBAtCR8k7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most prevalent form of breast cancer is Invasive Ductal Carcinoma (IDC). Pathologists usually concentrate on the areas of a whole mount sample that contain IDC to determine its aggressiveness grade. Consequently, a common preliminary step in automatically grading aggressiveness is to identify and outline the specific regions of IDC within a whole mount slide.\n",
        "\n",
        "The dataset comprises 279 patients' Whole Slide Imaging (WSI) images. A total of 277,524 patches measuring 50 x 50 were extracted from these images, consisting of 198,738 IDC-negative patches and 78,786 IDC-positive patches.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "b1nsNXrr8009"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "V961180v8_Ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import cv2 \n",
        "import glob\n",
        "import random\n",
        "from os import listdir\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "B2HZyo7w85fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Prep**\n"
      ],
      "metadata": {
        "id": "PjXXnA1J9Ib7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#getting all the images name for non IDC and IDC\n",
        "\n",
        "parent_dir = '/kaggle/input/breast-histopathology-images/IDC_regular_ps50_idx5/'\n",
        "dir_list = os.listdir(parent_dir)\n",
        "\n",
        "N_IDC = []\n",
        "P_IDC = []\n",
        "\n",
        "for dir_name in tqdm(dir_list):\n",
        "    \n",
        "    #getting all the IDC - images\n",
        "    negative_dir_path = os.path.join(parent_dir,dir_name,'0')\n",
        "    negative_image_path = []\n",
        "    for image_name in os.listdir(negative_dir_path):\n",
        "        negative_image_path.append(os.path.join(negative_dir_path, image_name))\n",
        "    N_IDC.extend(negative_image_path)\n",
        "    \n",
        "    #getting all the IDC + images\n",
        "    positive_dir_path = os.path.join(parent_dir,dir_name,'1')\n",
        "    positive_image_path = []\n",
        "    for image_name in os.listdir(positive_dir_path):\n",
        "        positive_image_path.append(os.path.join(positive_dir_path, image_name))\n",
        "    P_IDC.extend(positive_image_path)\n",
        "    \n",
        "    \n",
        "print(f'total number of IDC positive images {len(P_IDC)}')\n",
        "print(f'total number of IDC negative images {len(N_IDC)}')\n"
      ],
      "metadata": {
        "id": "a8vpX_1r9ZMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing Images**"
      ],
      "metadata": {
        "id": "2FFmHl-O9dPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.utils as image\n",
        "\n",
        "i = np.random.randint(0, len(N_IDC))\n",
        "img = image.load_img((N_IDC[i]), target_size=(100, 100))\n",
        "img = image.img_to_array(img)\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title('IDC (-)')\n",
        "plt.imshow(img.astype('uint8'))\n",
        "\n",
        "\n",
        "i = np.random.randint(0, len(P_IDC))\n",
        "img2 = image.load_img((P_IDC[i]), target_size=(100, 100))\n",
        "img2 = image.img_to_array(img2)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title('IDC (+)')\n",
        "plt.imshow(img2.astype('uint8'))\n"
      ],
      "metadata": {
        "id": "VxTrSpNn9ft_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reducing dataset due to computational constraints \n",
        "\n",
        "total_images = 50000\n",
        "n_img_arr = np.zeros(shape = (total_images,50,50,3),dtype = np.float32)\n",
        "p_img_arr = np.zeros(shape = (total_images,50,50,3),dtype = np.float32)\n",
        "label_n = []\n",
        "label_p = []\n",
        "\n",
        "\n",
        "for i,img in tqdm(enumerate(N_IDC[:total_images])):\n",
        "        \n",
        "    n_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "    n_img_size = cv2.resize(n_img, (50, 50), interpolation = cv2.INTER_LINEAR)\n",
        "    n_img_arr[i] = n_img_size\n",
        "    label_n.append(0)\n",
        "    \n",
        "for i,img in tqdm(enumerate(P_IDC[:total_images])):\n",
        "    c_img = cv2.imread(img, cv2.IMREAD_COLOR)\n",
        "    c_img_size = cv2.resize(c_img, (50, 50), interpolation = cv2.INTER_LINEAR)\n",
        "    p_img_arr[i] = c_img_size\n",
        "    label_p.append(1)\n",
        "    \n",
        "label_p = np.array(label_p)\n",
        "label_n = np.array(label_n)\n",
        "\n",
        "print(n_img_arr.shape,p_img_arr.shape)"
      ],
      "metadata": {
        "id": "zUxZzzpd9orT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preparing X array containing all the images and y array contains all the corresponding IDC class\n",
        "\n",
        "X = np.concatenate((p_img_arr, n_img_arr), axis = 0)\n",
        "y = np.concatenate((label_p, label_n), axis = 0)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "X, y = shuffle(X, y, random_state=0)\n",
        "\n",
        "print('Processed dataset size')\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "CBz72BOA9pfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#saving data as numpy array\n",
        "np.save('X.npy', X)\n",
        "np.save('y.npy', y)"
      ],
      "metadata": {
        "id": "jlN9AbLi9rV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#deleting variables to free up memories\n",
        "del p_img_arr\n",
        "del n_img_arr"
      ],
      "metadata": {
        "id": "rMGUwcxE9tvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "Y = to_categorical(y, num_classes = 2)\n",
        "print(Y[0],y[0])"
      ],
      "metadata": {
        "id": "U8EzZM1n9ugR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Splitting training and test set**"
      ],
      "metadata": {
        "id": "T5O-ZBqX9yuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#stratified to have balanced training and testing dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)\n",
        "print(\"Training Data Shape:\", X_train.shape)\n",
        "print(\"Testing Data Shape:\", X_test.shape)"
      ],
      "metadata": {
        "id": "lOCV37qK93qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#deleting variables to free up memories\n",
        "del X\n",
        "del y\n",
        "del Y"
      ],
      "metadata": {
        "id": "UltVfoih94pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training set size')\n",
        "print('IDC(-) Images: {}'.format(np.sum(Y_train==[1. ,0.])/2))\n",
        "print('IDC(+) Images: {}'.format(np.sum(Y_train==[0. ,1.])/2))\n",
        "\n",
        "print('Test set size')\n",
        "print('IDC(-) Images: {}'.format(np.sum(Y_test==[1. ,0.])/2))\n",
        "print('IDC(+) Images: {}'.format(np.sum(Y_test==[0. ,1.])/2))"
      ],
      "metadata": {
        "id": "smbppHSU97n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Preparation**"
      ],
      "metadata": {
        "id": "d8EZ9kse9_0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from keras.metrics import binary_crossentropy\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D,MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import itertools"
      ],
      "metadata": {
        "id": "w33ZTSdx-CO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing Model Prep**"
      ],
      "metadata": {
        "id": "MIgynTUc-Fq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(50, 50, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(24, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "2YGeodHS-Igp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "model.compile(Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss',patience=10)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, patience=3, min_lr=0.0001, mode = 'max')\n",
        "\n",
        "log_dir = os.getcwd() + f'/logs/'\n",
        "if not os.path.exists(log_dir):os.mkdir(log_dir)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = os.getcwd() +f'/classifier.h5',\n",
        "    save_weights_only = False,\n",
        "    save_freq = 'epoch',\n",
        "    monitor = 'val_accuracy',\n",
        "    mode = 'max',\n",
        "    save_best_only = True,\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "YpnLbR4t-Qqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, \n",
        "    Y_train, \n",
        "    validation_data = (X_test, Y_test), \n",
        "    epochs = 20,\n",
        "    batch_size = 32,\n",
        "    callbacks = [early_stop,\n",
        "                 reduce_lr,\n",
        "                 model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "XjdDdfZY-RE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Metrics of the trained model**"
      ],
      "metadata": {
        "id": "gDRMqgn--U-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vq8Rzww_-Wzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JOs3oKAp-YqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "Y_pred_classes = np.argmax(Y_pred,axis = 1) \n",
        "Y_true = np.argmax(Y_test,axis = 1) \n",
        "\n",
        "target_names = ['negative', 'positive']\n",
        "confusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \n",
        "f,ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"BuPu\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M7tCYZ-E-bik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#classification report of model\n",
        "print(classification_report(Y_true, Y_pred_classes, target_names=target_names))"
      ],
      "metadata": {
        "id": "fEnovTiu-dJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}